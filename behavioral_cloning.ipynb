{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = ['./data/trial3/', './data/trial4/', './data/trial5/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for location in data_dir:\n",
    "    df_ = pd.read_csv(location+'driving_log.csv', names=['center_cam', 'left_cam', 'right_cam', 'steering', 'throttle', 'brake', 'speed'])\n",
    "    # Rename data location\n",
    "    df_.iloc[:,0:3] = df_.iloc[:,0:3].apply(lambda x: location + 'IMG/' + x.str.split('\\\\').str[-1])\n",
    "    # Append to the training dataframe\n",
    "    df = pd.concat([df,df_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                          center_cam  \\\n",
       "0  ./data/trial3/IMG/center_2021_01_06_19_41_25_4...   \n",
       "1  ./data/trial3/IMG/center_2021_01_06_19_41_25_5...   \n",
       "2  ./data/trial3/IMG/center_2021_01_06_19_41_25_6...   \n",
       "3  ./data/trial3/IMG/center_2021_01_06_19_41_25_7...   \n",
       "4  ./data/trial3/IMG/center_2021_01_06_19_41_25_8...   \n",
       "\n",
       "                                            left_cam  \\\n",
       "0  ./data/trial3/IMG/left_2021_01_06_19_41_25_443...   \n",
       "1  ./data/trial3/IMG/left_2021_01_06_19_41_25_546...   \n",
       "2  ./data/trial3/IMG/left_2021_01_06_19_41_25_649...   \n",
       "3  ./data/trial3/IMG/left_2021_01_06_19_41_25_752...   \n",
       "4  ./data/trial3/IMG/left_2021_01_06_19_41_25_857...   \n",
       "\n",
       "                                           right_cam  steering  throttle  \\\n",
       "0  ./data/trial3/IMG/right_2021_01_06_19_41_25_44...       0.0       0.0   \n",
       "1  ./data/trial3/IMG/right_2021_01_06_19_41_25_54...       0.0       0.0   \n",
       "2  ./data/trial3/IMG/right_2021_01_06_19_41_25_64...       0.0       0.0   \n",
       "3  ./data/trial3/IMG/right_2021_01_06_19_41_25_75...       0.0       0.0   \n",
       "4  ./data/trial3/IMG/right_2021_01_06_19_41_25_85...       0.0       0.0   \n",
       "\n",
       "   brake     speed  \n",
       "0    0.0  0.000082  \n",
       "1    0.0  0.000078  \n",
       "2    0.0  0.000082  \n",
       "3    0.0  0.000078  \n",
       "4    0.0  0.000079  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>center_cam</th>\n      <th>left_cam</th>\n      <th>right_cam</th>\n      <th>steering</th>\n      <th>throttle</th>\n      <th>brake</th>\n      <th>speed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>./data/trial3/IMG/center_2021_01_06_19_41_25_4...</td>\n      <td>./data/trial3/IMG/left_2021_01_06_19_41_25_443...</td>\n      <td>./data/trial3/IMG/right_2021_01_06_19_41_25_44...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000082</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>./data/trial3/IMG/center_2021_01_06_19_41_25_5...</td>\n      <td>./data/trial3/IMG/left_2021_01_06_19_41_25_546...</td>\n      <td>./data/trial3/IMG/right_2021_01_06_19_41_25_54...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000078</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>./data/trial3/IMG/center_2021_01_06_19_41_25_6...</td>\n      <td>./data/trial3/IMG/left_2021_01_06_19_41_25_649...</td>\n      <td>./data/trial3/IMG/right_2021_01_06_19_41_25_64...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000082</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>./data/trial3/IMG/center_2021_01_06_19_41_25_7...</td>\n      <td>./data/trial3/IMG/left_2021_01_06_19_41_25_752...</td>\n      <td>./data/trial3/IMG/right_2021_01_06_19_41_25_75...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000078</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>./data/trial3/IMG/center_2021_01_06_19_41_25_8...</td>\n      <td>./data/trial3/IMG/left_2021_01_06_19_41_25_857...</td>\n      <td>./data/trial3/IMG/right_2021_01_06_19_41_25_85...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000079</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 15195 entries, 0 to 7327\nData columns (total 7 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   center_cam  15195 non-null  object \n 1   left_cam    15195 non-null  object \n 2   right_cam   15195 non-null  object \n 3   steering    15195 non-null  float64\n 4   throttle    15195 non-null  float64\n 5   brake       15195 non-null  float64\n 6   speed       15195 non-null  float64\ndtypes: float64(4), object(3)\nmemory usage: 949.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.DataFrame()\n",
    "# Series with all camera angles\n",
    "df_clean['camera'] = pd.concat([df['center_cam'], df['left_cam'], df['right_cam']])\n",
    "# Series with all steering angels (and modified steering angles)\n",
    "steering_offset = 0.02\n",
    "df_clean['steering'] = pd.concat([\n",
    "    df['steering'], \n",
    "    df['steering'].apply(lambda x: x + steering_offset),\n",
    "    df['steering'].apply(lambda x: x - steering_offset)\n",
    "    ])\n",
    "\n",
    "df_clean.reset_index(drop=True, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 45585 entries, 0 to 45584\nData columns (total 2 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   camera    45585 non-null  object \n 1   steering  45585 non-null  float64\ndtypes: float64(1), object(1)\nmemory usage: 712.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "source": [
    "## Generator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant preprocessing parameters\n",
    "sample_img = mpimg.imread(df_clean['camera'][0])\n",
    "scale_percent = 80 # percent of original size\n",
    "width = int(sample_img.shape[1] * scale_percent / 100)\n",
    "height = int(sample_img.shape[0] * scale_percent / 100)\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\n",
    "def preprocess(image):\n",
    "    '''\n",
    "    Preprocesses a given RGB image for input into the model.\n",
    "    :params image: RGB image as a numpy array\n",
    "    '''\n",
    "    normalized = image.copy()\n",
    "    normalized[:,:,0] = clahe.apply(normalized[:,:,0])\n",
    "    normalized[:,:,1] = clahe.apply(normalized[:,:,1])\n",
    "    normalized[:,:,2] = clahe.apply(normalized[:,:,2])\n",
    "    grayscale = cv2.cvtColor(normalized, cv2.COLOR_RGB2GRAY)\n",
    "    downscaled = cv2.resize(grayscale, (width, height), interpolation=cv2.INTER_AREA)\n",
    "    return downscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(Sequence):\n",
    "\n",
    "    def __init__(self, samples, batch_size):\n",
    "        self.samples = samples\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return np.ceil(len(self.samples) / self.batch_size).astype(np.int32)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        images = []\n",
    "        angles = []\n",
    "        # Read in images (and preprocess) and steering angles from the current batch\n",
    "        self.samples['camera'][idx * self.batch_size:(idx + 1) *\n",
    "        self.batch_size].apply(lambda x: images.append(preprocess(mpimg.imread(x))));\n",
    "        self.samples['steering'][idx * self.batch_size:(idx + 1) *\n",
    "        self.batch_size].apply(lambda x: angles.append(x));\n",
    "\n",
    "        X_train = np.expand_dims(np.array(images), axis=3)\n",
    "        y_train = np.array(angles)\n",
    "\n",
    "        return tuple(shuffle(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and validation samples\n",
    "train_samples, validation_samples = train_test_split(df_clean, test_size=0.2)\n",
    "\n",
    "# Set batch size\n",
    "batch_size=1024\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = Generator(train_samples, batch_size)\n",
    "validation_generator = Generator(validation_samples, batch_size)"
   ]
  },
  {
   "source": [
    "# Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Lambda, Flatten, Dense, Conv2D, MaxPool2D, Dropout, Cropping2D  \n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rezar\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Input Layer\n",
    "model.add(Lambda(lambda x: x/255.0 -0.5, input_shape=(height, width, 1)))\n",
    "model.add(Cropping2D(cropping=((40,10),(0,0))))\n",
    "# Convolution 1\n",
    "model.add(Conv2D(24, (5,5), strides=(2,2), activation='relu'))\n",
    "model.add(MaxPool2D(strides=(1,1)))\n",
    "# Convolution 2\n",
    "model.add(Conv2D(36, (5,5), strides=(2,2), activation='relu'))\n",
    "model.add(MaxPool2D(strides=(1,1)))\n",
    "# Convolution 3\n",
    "model.add(Conv2D(48, (5,5), strides=(2,2), activation='relu'))\n",
    "# Convolution 4\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPool2D(strides=(1,1)))\n",
    "# Convolution 5\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "# Flatten and Dropout\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.25))\n",
    "# Fully Connected 1\n",
    "model.add(Dense(400, activation='relu'))\n",
    "# Fully Connected 2\n",
    "model.add(Dense(100, activation='relu'))\n",
    "# Fully Connected 3 with Dropout\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# Output\n",
    "model.add(Dense(1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlambda (Lambda)              (None, 128, 256, 1)       0         \n_________________________________________________________________\ncropping2d (Cropping2D)      (None, 78, 256, 1)        0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 37, 126, 24)       624       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 36, 125, 24)       0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 16, 61, 36)        21636     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 15, 60, 36)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 6, 28, 48)         43248     \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 4, 26, 64)         27712     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 3, 25, 64)         0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 1, 23, 64)         36928     \n_________________________________________________________________\nflatten (Flatten)            (None, 1472)              0         \n_________________________________________________________________\ndropout (Dropout)            (None, 1472)              0         \n_________________________________________________________________\ndense (Dense)                (None, 400)               589200    \n_________________________________________________________________\ndense_1 (Dense)              (None, 100)               40100     \n_________________________________________________________________\ndense_2 (Dense)              (None, 50)                5050      \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 50)                0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 51        \n=================================================================\nTotal params: 764,549\nTrainable params: 764,549\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopper = EarlyStopping(monitor='val_loss', min_delta=0.0003, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0807 - acc: 0.0857Epoch 1/30\n",
      "36/36 [==============================] - 69s 2s/step - loss: 0.0802 - acc: 0.0853 - val_loss: 0.0574 - val_acc: 0.0857\n",
      "Epoch 2/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0584 - acc: 0.0857Epoch 1/30\n",
      "36/36 [==============================] - 56s 2s/step - loss: 0.0582 - acc: 0.0856 - val_loss: 0.0486 - val_acc: 0.0865\n",
      "Epoch 3/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0503 - acc: 0.0863Epoch 1/30\n",
      "36/36 [==============================] - 56s 2s/step - loss: 0.0503 - acc: 0.0863 - val_loss: 0.0436 - val_acc: 0.0869\n",
      "Epoch 4/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0463 - acc: 0.0870Epoch 1/30\n",
      "36/36 [==============================] - 56s 2s/step - loss: 0.0461 - acc: 0.0868 - val_loss: 0.0403 - val_acc: 0.0877\n",
      "Epoch 5/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0415 - acc: 0.0873Epoch 1/30\n",
      "36/36 [==============================] - 56s 2s/step - loss: 0.0415 - acc: 0.0874 - val_loss: 0.0360 - val_acc: 0.0887\n",
      "Epoch 6/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0402 - acc: 0.0877Epoch 1/30\n",
      "36/36 [==============================] - 55s 2s/step - loss: 0.0402 - acc: 0.0879 - val_loss: 0.0369 - val_acc: 0.0884\n",
      "Epoch 7/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0371 - acc: 0.0880Epoch 1/30\n",
      "36/36 [==============================] - 57s 2s/step - loss: 0.0370 - acc: 0.0881 - val_loss: 0.0313 - val_acc: 0.0893\n",
      "Epoch 8/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0340 - acc: 0.0888Epoch 1/30\n",
      "36/36 [==============================] - 56s 2s/step - loss: 0.0340 - acc: 0.0888 - val_loss: 0.0307 - val_acc: 0.0892\n",
      "Epoch 9/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0327 - acc: 0.0889Epoch 1/30\n",
      "36/36 [==============================] - 56s 2s/step - loss: 0.0327 - acc: 0.0891 - val_loss: 0.0272 - val_acc: 0.0901\n",
      "Epoch 10/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0294 - acc: 0.0894Epoch 1/30\n",
      "36/36 [==============================] - 56s 2s/step - loss: 0.0293 - acc: 0.0893 - val_loss: 0.0262 - val_acc: 0.0902\n",
      "Epoch 11/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0279 - acc: 0.0892Epoch 1/30\n",
      "36/36 [==============================] - 56s 2s/step - loss: 0.0279 - acc: 0.0895 - val_loss: 0.0268 - val_acc: 0.0904\n",
      "Epoch 12/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0268 - acc: 0.0895Epoch 1/30\n",
      "36/36 [==============================] - 57s 2s/step - loss: 0.0267 - acc: 0.0896 - val_loss: 0.0242 - val_acc: 0.0903\n",
      "Epoch 13/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0247 - acc: 0.0898Epoch 1/30\n",
      "36/36 [==============================] - 56s 2s/step - loss: 0.0246 - acc: 0.0898 - val_loss: 0.0222 - val_acc: 0.0908\n",
      "Epoch 14/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0235 - acc: 0.0903Epoch 1/30\n",
      "36/36 [==============================] - 56s 2s/step - loss: 0.0236 - acc: 0.0898 - val_loss: 0.0217 - val_acc: 0.0908\n",
      "Epoch 15/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0224 - acc: 0.0898Epoch 1/30\n",
      "36/36 [==============================] - 56s 2s/step - loss: 0.0224 - acc: 0.0899 - val_loss: 0.0211 - val_acc: 0.0907\n",
      "Epoch 16/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0214 - acc: 0.0899Epoch 1/30\n",
      "36/36 [==============================] - 56s 2s/step - loss: 0.0214 - acc: 0.0902 - val_loss: 0.0191 - val_acc: 0.0907\n",
      "Epoch 17/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0205 - acc: 0.0901Epoch 1/30\n",
      "36/36 [==============================] - 56s 2s/step - loss: 0.0205 - acc: 0.0903 - val_loss: 0.0192 - val_acc: 0.0907\n",
      "Epoch 18/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0199 - acc: 0.0903Epoch 1/30\n",
      "36/36 [==============================] - 57s 2s/step - loss: 0.0199 - acc: 0.0903 - val_loss: 0.0184 - val_acc: 0.0908\n",
      "Epoch 19/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0196 - acc: 0.0902Epoch 1/30\n",
      "36/36 [==============================] - 56s 2s/step - loss: 0.0196 - acc: 0.0901 - val_loss: 0.0197 - val_acc: 0.0906\n",
      "Epoch 20/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0188 - acc: 0.0907Epoch 1/30\n",
      "36/36 [==============================] - 57s 2s/step - loss: 0.0188 - acc: 0.0904 - val_loss: 0.0176 - val_acc: 0.0909\n",
      "Epoch 21/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0181 - acc: 0.0903Epoch 1/30\n",
      "36/36 [==============================] - 57s 2s/step - loss: 0.0181 - acc: 0.0904 - val_loss: 0.0178 - val_acc: 0.0908\n",
      "Epoch 22/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0172 - acc: 0.0905Epoch 1/30\n",
      "36/36 [==============================] - 56s 2s/step - loss: 0.0172 - acc: 0.0904 - val_loss: 0.0173 - val_acc: 0.0909\n",
      "Epoch 23/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0168 - acc: 0.0901Epoch 1/30\n",
      "36/36 [==============================] - 56s 2s/step - loss: 0.0167 - acc: 0.0903 - val_loss: 0.0161 - val_acc: 0.0909\n",
      "Epoch 24/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0161 - acc: 0.0907Epoch 1/30\n",
      "36/36 [==============================] - 56s 2s/step - loss: 0.0161 - acc: 0.0905 - val_loss: 0.0170 - val_acc: 0.0909\n",
      "Epoch 25/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0155 - acc: 0.0905Epoch 1/30\n",
      "36/36 [==============================] - 56s 2s/step - loss: 0.0155 - acc: 0.0905 - val_loss: 0.0158 - val_acc: 0.0910\n",
      "Epoch 26/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0151 - acc: 0.0903Epoch 1/30\n",
      "36/36 [==============================] - 56s 2s/step - loss: 0.0151 - acc: 0.0905 - val_loss: 0.0153 - val_acc: 0.0910\n",
      "Epoch 27/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0149 - acc: 0.0906Epoch 1/30\n",
      "36/36 [==============================] - 56s 2s/step - loss: 0.0150 - acc: 0.0904 - val_loss: 0.0160 - val_acc: 0.0909\n",
      "Epoch 28/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0149 - acc: 0.0906Epoch 1/30\n",
      "36/36 [==============================] - 56s 2s/step - loss: 0.0149 - acc: 0.0906 - val_loss: 0.0149 - val_acc: 0.0910\n",
      "Epoch 29/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0141 - acc: 0.0904Epoch 1/30\n",
      "36/36 [==============================] - 57s 2s/step - loss: 0.0141 - acc: 0.0905 - val_loss: 0.0148 - val_acc: 0.0910\n",
      "Epoch 30/30\n",
      "35/36 [============================>.] - ETA: 1s - loss: 0.0141 - acc: 0.0906Epoch 1/30\n",
      "36/36 [==============================] - 56s 2s/step - loss: 0.0141 - acc: 0.0904 - val_loss: 0.0152 - val_acc: 0.0909\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit_generator(train_generator, \n",
    "    steps_per_epoch=np.ceil(len(train_samples)/batch_size),\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=np.ceil(len(validation_samples)/batch_size),\n",
    "    epochs=30,\n",
    "    callbacks=[stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train[400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(np.expand_dims(X_train_modified[400], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %run drive.py model.h5"
   ]
  },
  {
   "source": [
    "# Fine-Tuning\n",
    "Instead of re-training the network from scratch, this section can be modified to train on additional data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = ['./data/trial3/', './data/trial4/', './data/trial5/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame()\n",
    "# for location in data_dir:\n",
    "#     df_ = pd.read_csv(location+'driving_log.csv', names=['center_cam', 'left_cam', 'right_cam', 'steering', 'throttle', 'brake', 'speed'])\n",
    "#     # Rename data location\n",
    "#     df_.iloc[:,0:3] = df_.iloc[:,0:3].apply(lambda x: location + 'IMG/' + x.str.split('\\\\').str[-1])\n",
    "#     # Append to the training dataframe\n",
    "#     df = pd.concat([df,df_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = []\n",
    "# measurements = []\n",
    "\n",
    "# df_clean['center_cam'].apply(lambda x: images.append(mpimg.imread(x)));\n",
    "# df_clean['steering'].apply(lambda x: measurements.append(x));\n",
    "# steering_offset = 0.02\n",
    "# # Left Camera Modifications\n",
    "# df_clean['left_cam'].apply(lambda x: images.append(mpimg.imread(x)));\n",
    "# df_clean['steering'].apply(lambda x: measurements.append(x + steering_offset));\n",
    "# # Right Camera Modifications\n",
    "# df_clean['right_cam'].apply(lambda x: images.append(mpimg.imread(x)));\n",
    "# df_clean['steering'].apply(lambda x: measurements.append(x - steering_offset));\n",
    "\n",
    "# X_train = np.array(images)\n",
    "# y_train = np.array(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified_images =[]\n",
    "\n",
    "# scale_percent = 80 # percent of original size\n",
    "# width = int(X_train[0].shape[1] * scale_percent / 100)\n",
    "# height = int(X_train[0].shape[0] * scale_percent / 100)\n",
    "# dim = (width, height)\n",
    "\n",
    "# clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "# for image in X_train:\n",
    "#     normalized = image.copy()\n",
    "#     normalized[:,:,0] = clahe.apply(normalized[:,:,0])\n",
    "#     normalized[:,:,1] = clahe.apply(normalized[:,:,1])\n",
    "#     normalized[:,:,2] = clahe.apply(normalized[:,:,2])\n",
    "#     grayscale = cv2.cvtColor(normalized, cv2.COLOR_RGB2GRAY)\n",
    "#     downscaled = cv2.resize(grayscale, dim, interpolation=cv2.INTER_AREA)\n",
    "#     modified_images.append(downscaled)\n",
    "\n",
    "# X_train_modified = np.array(modified_images)\n",
    "# # Adding a dimension for Keras processing purposes\n",
    "# X_train_modified = np.expand_dims(X_train_modified, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "# tf.keras.backend.clear_session()\n",
    "# model = load_model('model.h5')\n",
    "\n",
    "# log_dir = \"logs\\\\fit\\\\\"\n",
    "# tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# stopper = EarlyStopping(monitor='val_loss', min_delta=0.0003, patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "# model.fit(X_train_modified, y_train, epochs=30, batch_size=256, validation_split=0.2, shuffle=True, callbacks=[tensorboard_callback, stopper])\n",
    "# model.save('model_fine_tune.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}